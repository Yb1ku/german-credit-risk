{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CREDIT RISK CLASSIFICATION","text":"<p>Documentation for the Credit Risk Classification project. This site includes: </p> <ul> <li>Dataset description </li> <li>Exploratory Data Analysis (EDA) </li> <li>Model training and evaluation </li> <li>Hyperparameter tuning </li> <li>Feature importance analysis via SHAP </li> <li>Model deployment with FastAPI </li> </ul>"},{"location":"eda/dataset_overview/","title":"Dataset overview","text":""},{"location":"eda/dataset_overview/#dataset-overview","title":"\ud83d\udcc7 DATASET OVERVIEW","text":"<p>The data used in this project is the  German Credit Data  dataset, which contains information about credit applicants and their credit risk  classification. The dataset consists of 1000 samples. There are 2 variations of the  dataset: </p> <ul> <li>German Data: Contains both categorical and numerical features. </li> <li>German Data Numeric: Categorical features are encoded as numerical values.  Suitable for models that require numerical inputs. </li> </ul> <p>This project uses the original German Data with categorical features. </p>"},{"location":"eda/dataset_overview/#features","title":"FEATURES","text":"<p>The dataset contains 20 features and a target variable. The features are a mix of  categorical and numerical variables: </p> Feature Name Type Description Checking_account_status Categorical Status of existing checking account Duration_months Numerical Duration in months Credit_history Categorical Credit history of the applicant Purpose Categorical Purpose of the credit Credit_amount Numerical Amount of credit Savings_account_bonds Categorical Savings account or bonds Employment_since Categorical Present employment duration Installment_rate Numerical Installment rate in % of disposable income Personal_status_sex Categorical Personal status and sex Other_debtors_guarantors Categorical Other debtors or guarantors Residence_since Numerical Present residence duration in years Property Categorical Type of property Age_years Numerical Age of the applicant Other_installment_plans Categorical Other installment plans (e.g. bank, stores) Housing Categorical Type of housing Existing_credits Numerical Number of existing credits at this bank Job Categorical Job category Maintenance_people Numerical Number of people liable for maintenance Telephone Categorical Presence of telephone (registered under the customer's name or not) Foreign_worker Categorical Whether the applicant is a foreign worker <p>The next step is to perform exploratory data analysis (EDA) to understand the  underlying patterns and relationships in the data. This will help in feature  selection and model building stages. </p>"},{"location":"eda/exploration/","title":"Exploratory Data Analysis","text":""},{"location":"eda/exploration/#exploratory-data-analysis-eda","title":"\ud83d\udcca Exploratory Data Analysis (EDA)","text":"<p>The exploratory data analysis (EDA) is the first step in a machine learning project,  as it helps to understand the data one is working with. As an attempt to simulate a real world scenario, the EDA has been performed with the dataset converted to a  SQL database. The EDA is performed using SQL queries to extract the data and matplotlib  to visualize it. For more details on the queries used please refer to the  queries section. </p> <p>Here are the graphs generated during the EDA: </p> <p> </p>"},{"location":"eda/exploration/#key-findings","title":"\ud83d\udcc8 Key Findings","text":"<p>The first thing to notice is the imbalance in the target variable. 70% of the  applicants have a good credit risk, while 30% have a bad credit risk. This is  a common scenario in real world datasets, where the positive class outnumbers the negative one. When training the model, it will be important to keep this in mind,  as class balancing techniques may be needed. Also, accuracy and recall analysis  will be important to ensure that the model is not biased towards the majority  class.</p> <p>When looking at the credit amount, the mean amount is around 4.000 for bad risk  applicants, and around 3.000 for good risk applicants. This suggests that credit  amount could be a good feature to use in the model. </p> <p>The age most frequent age group in the dataset is the 25-34 segment, which is  somewhat expected, as this is the age group that is most likely to apply for a  credit. Looking at the personal status, the majority of the applicants are single  men (A93). Something that stands out is the absence of A95 applicants(female,  single). This suggests that, fore some reason, single men are more likely to  apply for a credit than single women. However, this issue is not within the scope  of this project. </p> <p>In terms of housing, the majority of the applicants are owners (A152). Being an  owner may be a good indicator of good credit risk, as the majority of the  applicants who fall into this category have a good credit risk. On the other hand,  both A151 (renting) and A153 (for free) don't have enough data to draw any  conclusions. </p> <p>50% of the applicants are type A32 in credit history, which means they have paid  all their previous credits. This could be a good indicator of good credit risk, but it would not be prudent to draw any conclusions based on this alone. </p> <p>Looking at the guarantor types, the distributions is quite even, so this variable  is not likely to be a good indicator of credit risk. However, the variable could  still be useful in the model. </p> <p>With this information, the next step is to build a base model and evaluate it.  Even though the EDA has provided some insights, it can still be improved with  further analysis. </p>"},{"location":"modeling/baseline_model/","title":"Baseline model","text":""},{"location":"modeling/baseline_model/#building-a-baseline-model","title":"BUILDING A BASELINE MODEL","text":"<p>This section explains how the baseline model was built. It is a simple XGBoost model with default hyperparameters. Even though it is not optimized, and hyperparameter  tuning is an essential step in the machine learning pipeline, it is a good starting  point. Also, with some metrics obtained by this model, one can keep track of the  improvement of the model after hyperparameter tuning and feature engineering. </p> <p>The first step is to load the data from the database. For this project, the data  was loaded as follows: </p> <pre><code>import pandas as pd \nimport sqlite3 \n\nconn = sqlite3.connect(\"german_credit.db\")\n\nextract_query = \"\"\"\nSELECT * FROM credit;\n\"\"\"\ndata = pd.read_sql_query(extract_query, conn)\nx = data.drop(columns=[\"Target\"])\nfor col in x.select_dtypes(include=\"object\").columns:\n    x[col] = x[col].astype(\"category\")\ny = data[\"Target\"]\n</code></pre> <p>Now, <code>x</code> is a DataFrame containing all the examples and features, and <code>y</code> contains  the target variable for each example. </p> <p>For the baseline model, the <code>XGBoostClassifier</code> from the <code>xgboost</code> library was used.  This model does not require any preprocessing of the data, as it can handle both  numerical and categorical features. The model was trained with the default hyperparameters,  using a cross-validation strategy to evaluate via <code>StratifiedKFold</code> with 5 folds.</p> <pre><code>from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\n\nmodel = xgb.XGBClassifier(\n    objective=\"binary:logistic\",\n    eval_metric=\"logloss\",\n    enable_categorical=True,\n    random_state=42\n)\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nacc_scores, recall_scores, f1_scores, auc_scores = [], [], [], []\nfor fold, (train_idx, test_idx) in enumerate(skf.split(x, y), 1):\n    x_train, x_test = x.iloc[train_idx], x.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    y_proba = model.predict_proba(x_test)[:, 1]\n\n    acc_scores.append(accuracy_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))\n    auc_scores.append(roc_auc_score(y_test, y_proba))\n</code></pre> <p>The model obtained the following metrics, averaged across the 5 folds: </p> Metric Value Accuracy 0.7540 Recall 0.8643 F1 Score 0.8310 AUC 0.7630 <p>Even though the model was a simple baseline with default hyperparameters, it is still a good starting point. The model correctly classified 75.40% of the examples, while  maintaining 86.43% of the true positives among all real positive cases. The AUC  score of 0.7630 indicates that the model has a good ability to discriminate between  the positive and negative classes. However, there is still room for improvement.  In the next section, a hyperparameter tuning process will be carried out to further improve the model's performance. </p>"},{"location":"modeling/hyperparameter_tuning/","title":"Hyperparameter Tuning","text":""},{"location":"modeling/hyperparameter_tuning/#hyperparameter-tuning","title":"HYPERPARAMETER TUNING","text":"<p>The previous section introduced a baseline model with default hyperparameters. Now,  the goal is to improve the model's performance by tuning its hyperparameters. This  process has been carried out using a simple grid search strategy. It may not be the  most complex or exhaustive method, but it is a good starting point for hyperparameter tuning. If the model's performance is still not satisfactory, more advanced techniques can be applied. </p> <p>The hyperparameter search has been performed as follows: </p> <pre><code>from sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import make_scorer, f1_score\nimport xgboost as xgb\n\nbase_model = xgb.XGBClassifier(\n    objective=\"binary:logistic\",\n    eval_metric=\"logloss\",\n    enable_categorical=True,\n    random_state=42\n)\n\nparam_grid = {\n    \"max_depth\": [3, 5, 7],\n    \"learning_rate\": [0.01, 0.1, 0.2],\n    \"n_estimators\": [100, 200],\n    \"subsample\": [0.8, 1],\n    \"colsample_bytree\": [0.8, 1],\n}\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ngrid_search = GridSearchCV(\n    estimator=base_model,\n    param_grid=param_grid,\n    scoring=make_scorer(f1_score),\n    cv=cv,\n    verbose=1,\n    n_jobs=-1\n)\n\ngrid_search.fit(x, y)\n</code></pre> <p>The optimal hyperparameters found are: </p> <pre><code>{\n    'colsample_bytree': 0.8,\n    'learning_rate': 0.1, \n    'max_depth': 3,\n    'n_estimators': 200, \n    'subsample': 1\n}\n</code></pre> <p>The model achieved the following performance metrics, averaged over the 5-fold  cross-validation process: </p> Metric Value Improvement Accuracy 0.8461 +0.0921 Recall 0.9743 +0.11 F1 Score 0.9472 +0.1162 AUC 0.9744 +0.2114 <p>With this simple grid search, the model's performance has been significantly  improved. The metrics show the model's performance is now much better than the  baseline model. Even though there is still room for improvement, the extra boost in  performance that could be achieved with more advanced hyperparameter tuning techniques  and with feature engineering is not worth the extra time and complexity. It is good  to boost the performance, but it is also important to keep the model nice and simple. </p> <p>The next section will focus on explaining the model's predictions using SHAP. </p>"}]}